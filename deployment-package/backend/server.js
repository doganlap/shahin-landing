require('dotenv').config();
const express = require('express');
const cors = require('cors');
const multer = require('multer');
const fetch = require('node-fetch'); // Add this dependency
const app = express();
const PORT = process.env.PORT || 3001;

// AI Service Providers Configuration
const AI_SERVICES = {
  AZURE_OPENAI: {
    endpoint: process.env.AZURE_OPENAI_ENDPOINT,
    key: process.env.AZURE_OPENAI_KEY,
    enabled: !!(process.env.AZURE_OPENAI_ENDPOINT && process.env.AZURE_OPENAI_KEY)
  },
  AZURE_COGNITIVE: {
    visionEndpoint: process.env.AZURE_COMPUTER_VISION_ENDPOINT,
    speechEndpoint: process.env.AZURE_SPEECH_ENDPOINT,
    key: process.env.AZURE_COGNITIVE_KEY,
    enabled: !!(process.env.AZURE_COMPUTER_VISION_ENDPOINT && process.env.AZURE_COGNITIVE_KEY)
  },
  OPENAI_PUBLIC: {
    endpoint: 'https://api.openai.com/v1',
    key: process.env.OPENAI_API_KEY,
    enabled: !!process.env.OPENAI_API_KEY
  },
  HUGGINGFACE: {
    endpoint: 'https://api-inference.huggingface.co',
    key: process.env.HUGGINGFACE_API_KEY,
    enabled: !!process.env.HUGGINGFACE_API_KEY
  }
};

// Middleware - CORS Configuration for Production
const corsOptions = {
  origin: [
    'http://localhost:3000',
    'http://localhost:4000', 
    'http://localhost:4001',
    'https://shahin-ai.com',
    'https://www.shahin-ai.com',
    'https://landing.shahin-ai.com'
  ],
  credentials: true,
  methods: ['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS'],
  allowedHeaders: ['Content-Type', 'Authorization', 'X-Requested-With']
};

app.use(cors(corsOptions));
app.use(express.json({ limit: '10mb' }));
app.use(express.urlencoded({ extended: true, limit: '10mb' }));

// Configure multer for file uploads
const storage = multer.memoryStorage();
const upload = multer({ 
  storage: storage,
  limits: {
    fileSize: 10 * 1024 * 1024 // 10MB limit
  }
});

// Intelligent AI Service Router
const routeToAvailableAI = async (requestType, data) => {
  const errors = [];

  // Try Azure OpenAI first for chat and image tasks
  if ((requestType === 'chat' || requestType === 'image') && AI_SERVICES.AZURE_OPENAI.enabled) {
    try {
      const response = await callAzureOpenAI(requestType, data);
      if (response) return { source: 'Azure OpenAI', ...response };
    } catch (error) {
      errors.push(`Azure OpenAI: ${error.message}`);
    }
  }

  // Try Azure Cognitive Services for image and speech
  if ((requestType === 'image' || requestType === 'voice') && AI_SERVICES.AZURE_COGNITIVE.enabled) {
    try {
      const response = await callAzureCognitive(requestType, data);
      if (response) return { source: 'Azure Cognitive Services', ...response };
    } catch (error) {
      errors.push(`Azure Cognitive: ${error.message}`);
    }
  }

  // Try OpenAI Public API
  if ((requestType === 'chat' || requestType === 'image') && AI_SERVICES.OPENAI_PUBLIC.enabled) {
    try {
      const response = await callOpenAIPublic(requestType, data);
      if (response) return { source: 'OpenAI API', ...response };
    } catch (error) {
      errors.push(`OpenAI Public: ${error.message}`);
    }
  }

  // Try Hugging Face as fallback
  if (AI_SERVICES.HUGGINGFACE.enabled) {
    try {
      const response = await callHuggingFace(requestType, data);
      if (response) return { source: 'Hugging Face', ...response };
    } catch (error) {
      errors.push(`Hugging Face: ${error.message}`);
    }
  }

  // If all fail, return local fallback
  console.log('Using local fallback - Service errors:', errors.join('; '));
  return { source: 'Local Fallback (Smart Routing)', ...generateLocalResponse(requestType, data) };
};

// Azure OpenAI Integration
const callAzureOpenAI = async (requestType, data) => {
  const { endpoint, key } = AI_SERVICES.AZURE_OPENAI;
  
  if (requestType === 'chat') {
    const response = await fetch(`${endpoint}/openai/deployments/gpt-4/chat/completions?api-version=2024-02-15-preview`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'api-key': key
      },
      body: JSON.stringify({
        messages: [
          {
            role: 'system',
            content: 'Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ø§Ù„Ø­ÙˆÙƒÙ…Ø© ÙˆØ¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø± ÙˆØ§Ù„Ø§Ù…ØªØ«Ø§Ù„ Ù„Ù„Ø´Ø±ÙƒØ§Øª Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©. ØªØ¬ÙŠØ¨ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¯Ø§Ø¦Ù…Ø§Ù‹.'
          },
          {
            role: 'user',
            content: data.message
          }
        ],
        max_tokens: 500,
        temperature: 0.7
      })
    });

    if (response.ok) {
      const result = await response.json();
      return {
        message: result.choices?.[0]?.message?.content || 'ØªÙ… Ø§Ù„Ø±Ø¯ Ø¨Ù†Ø¬Ø§Ø­',
        type: 'text'
      };
    }
  } else if (requestType === 'image') {
    const response = await fetch(`${endpoint}/openai/deployments/gpt-4-vision/chat/completions?api-version=2024-02-15-preview`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'api-key': key
      },
      body: JSON.stringify({
        messages: [
          {
            role: 'user',
            content: [
              {
                type: 'text',
                text: 'Ø­Ù„Ù„ Ù‡Ø°Ù‡ Ø§Ù„ØµÙˆØ±Ø© ÙˆØ§Ø´Ø±Ø­ Ù…Ø­ØªÙˆØ§Ù‡Ø§ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©ØŒ Ù…Ø¹ Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ø§Ù„Ø£Ø¹Ù…Ø§Ù„ Ø£Ùˆ Ø§Ù„Ø­ÙˆÙƒÙ…Ø©.'
              },
              {
                type: 'image_url',
                image_url: {
                  url: data.image
                }
              }
            ]
          }
        ],
        max_tokens: 500
      })
    });

    if (response.ok) {
      const result = await response.json();
      return {
        analysis: result.choices?.[0]?.message?.content || 'ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ù†Ø¬Ø§Ø­',
        confidence: 0.9
      };
    }
  }

  throw new Error('Azure OpenAI request failed');
};

// Azure Cognitive Services Integration
const callAzureCognitive = async (requestType, data) => {
  if (requestType === 'image') {
    const { visionEndpoint, key } = AI_SERVICES.AZURE_COGNITIVE;
    
    const response = await fetch(`${visionEndpoint}/vision/v3.2/analyze?visualFeatures=Description,Tags,Objects&language=ar`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Ocp-Apim-Subscription-Key': key
      },
      body: JSON.stringify({
        url: data.image.startsWith('http') ? data.image : null
      })
    });

    if (response.ok) {
      const result = await response.json();
      return {
        analysis: result.description?.captions?.[0]?.text || 'ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ù†Ø¬Ø§Ø­',
        confidence: result.description?.captions?.[0]?.confidence || 0.8,
        tags: result.tags?.map(tag => tag.name) || []
      };
    }
  }

  throw new Error('Azure Cognitive Services request failed');
};

// OpenAI Public API Integration
const callOpenAIPublic = async (requestType, data) => {
  const { endpoint, key } = AI_SERVICES.OPENAI_PUBLIC;

  if (requestType === 'chat') {
    const response = await fetch(`${endpoint}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${key}`
      },
      body: JSON.stringify({
        model: 'gpt-3.5-turbo',
        messages: [
          {
            role: 'system',
            content: 'You are an AI assistant specializing in governance, risk management, and compliance for Saudi companies. Always respond in Arabic.'
          },
          {
            role: 'user',
            content: data.message
          }
        ],
        max_tokens: 500,
        temperature: 0.7
      })
    });

    if (response.ok) {
      const result = await response.json();
      return {
        message: result.choices?.[0]?.message?.content || 'ØªÙ… Ø§Ù„Ø±Ø¯ Ø¨Ù†Ø¬Ø§Ø­',
        type: 'text'
      };
    } else {
      const errorText = await response.text();
      console.error('OpenAI API Error:', response.status, errorText);
      
      if (response.status === 429) {
        throw new Error('OpenAI API quota exceeded - please check billing');
      } else if (response.status === 401) {
        throw new Error('OpenAI API authentication failed - invalid key');
      } else {
        throw new Error(`OpenAI API failed: ${response.status} - ${errorText}`);
      }
    }
  }

  throw new Error('OpenAI Public API request failed - unsupported request type');
};

// Hugging Face Integration
const callHuggingFace = async (requestType, data) => {
  const { endpoint, key } = AI_SERVICES.HUGGINGFACE;

  if (requestType === 'chat') {
    const response = await fetch(`${endpoint}/models/microsoft/DialoGPT-large`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${key}`
      },
      body: JSON.stringify({
        inputs: data.message
      })
    });

    if (response.ok) {
      const result = await response.json();
      return {
        message: Array.isArray(result) ? result[0]?.generated_text : 'ØªÙ… Ø§Ù„Ø±Ø¯ Ø¨Ù†Ø¬Ø§Ø­',
        type: 'text'
      };
    }
  } else if (requestType === 'image') {
    const response = await fetch(`${endpoint}/models/Salesforce/blip-image-captioning-large`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${key}`
      },
      body: JSON.stringify({
        inputs: data.image
      })
    });

    if (response.ok) {
      const result = await response.json();
      return {
        analysis: Array.isArray(result) ? result[0]?.generated_text : 'ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©',
        confidence: 0.7
      };
    }
  }

  throw new Error('Hugging Face request failed');
};

// Local fallback responses
const generateLocalResponse = (requestType, data) => {
  const responses = {
    general: [
      'Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ø´Ø§Ù‡ÙŠÙ† Ù„Ù„Ø­ÙˆÙƒÙ…Ø©! ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„ÙŠÙˆÙ…ØŸ',
      'Ø£Ù†Ø§ Ù‡Ù†Ø§ Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø± ÙˆØ§Ù„Ø§Ù…ØªØ«Ø§Ù„. Ù…Ø§ Ø§Ù„Ø°ÙŠ ØªØ­ØªØ§Ø¬ Ø¥Ù„ÙŠÙ‡ØŸ',
      'ÙŠØ³Ø¹Ø¯Ù†ÙŠ Ø£Ù† Ø£Ø³Ø§Ø¹Ø¯Ùƒ ÙÙŠ Ø­Ù„ÙˆÙ„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ù„Ø­ÙˆÙƒÙ…Ø©.',
    ],
    analysis: [
      'Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ØŒ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø£Ù† Ø£Ø³Ø§Ø¹Ø¯Ùƒ ÙÙŠ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø®Ø§Ø·Ø± ÙˆØªØ­Ø³ÙŠÙ† Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„.',
      'ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­. Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ØªØ´ÙŠØ± Ø¥Ù„Ù‰ ÙØ±Øµ ØªØ­Ø³ÙŠÙ† ÙÙŠ Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø­ÙˆÙƒÙ…Ø©.',
    ],
    pricing: [
      'Ù†Ù‚Ø¯Ù… Ø¨Ø§Ù‚Ø§Øª Ù…Ø±Ù†Ø© ØªØ¨Ø¯Ø£ Ù…Ù† 500 Ø±ÙŠØ§Ù„ Ø´Ù‡Ø±ÙŠØ§Ù‹ Ù„Ù„Ø´Ø±ÙƒØ§Øª Ø§Ù„ØµØºÙŠØ±Ø© ÙˆØ­ØªÙ‰ Ø§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„Ù…Ø¤Ø³Ø³ÙŠØ©.',
      'ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ¬Ø±Ø¨Ø© Ù…Ø¬Ø§Ù†ÙŠØ© Ù„Ù…Ø¯Ø© 30 ÙŠÙˆÙ…Ø§Ù‹ Ù„ØªÙ‚ÙŠÙŠÙ… Ù…Ù†ØµØªÙ†Ø§.',
    ],
    compliance: [
      'Ù†Ø³Ø§Ø¹Ø¯Ùƒ ÙÙŠ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø­ÙˆÙƒÙ…Ø© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© ÙˆÙ…ØªØ·Ù„Ø¨Ø§Øª Ù‡ÙŠØ¦Ø© Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ù…Ø§Ù„ÙŠØ©.',
      'Ù…Ù†ØµØªÙ†Ø§ ØªØ¯Ø¹Ù… Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø·Ø± Ø§Ù„ØªÙ†Ø¸ÙŠÙ…ÙŠØ© Ø§Ù„Ù…Ø­Ù„ÙŠØ© ÙˆØ§Ù„Ø¯ÙˆÙ„ÙŠØ©.',
    ]
  };

  const getRandomResponse = (category) => {
    const categoryResponses = responses[category] || responses.general;
    return categoryResponses[Math.floor(Math.random() * categoryResponses.length)];
  };

  if (data.message) {
    const message = data.message.toLowerCase();
    if (message.includes('Ø³Ø¹Ø±') || message.includes('ØªÙƒÙ„ÙØ©') || message.includes('Ø¨Ø§Ù‚Ø©')) {
      return { message: getRandomResponse('pricing') };
    } else if (message.includes('Ø§Ù…ØªØ«Ø§Ù„') || message.includes('Ù‚Ø§Ù†ÙˆÙ†') || message.includes('Ù†Ø¸Ø§Ù…')) {
      return { message: getRandomResponse('compliance') };
    } else if (message.includes('ØªØ­Ù„ÙŠÙ„') || message.includes('ØªÙ‚Ø±ÙŠØ±') || message.includes('Ø¨ÙŠØ§Ù†Ø§Øª')) {
      return { message: getRandomResponse('analysis') };
    }
  }

  return { 
    message: getRandomResponse('general'),
    note: 'Using local fallback - OpenAI quota may be exceeded'
  };
};

// API Routes

// Enhanced health check with multi-service status
app.get('/api/ai/health', (req, res) => {
  const serviceStatus = {};
  let availableCapabilities = ['chat_fallback', 'image_fallback', 'document_analysis', 'voice_processing'];

  // Check each AI service status
  if (AI_SERVICES.AZURE_OPENAI.enabled) {
    serviceStatus.azureOpenAI = 'configured';
    availableCapabilities.push('azure_chat', 'azure_vision');
  }

  if (AI_SERVICES.AZURE_COGNITIVE.enabled) {
    serviceStatus.azureCognitive = 'configured';
    availableCapabilities.push('azure_vision', 'azure_speech');
  }

  if (AI_SERVICES.OPENAI_PUBLIC.enabled) {
    serviceStatus.openAIPublic = 'configured_quota_check_needed';
    availableCapabilities.push('openai_chat', 'openai_vision');
  }

  if (AI_SERVICES.HUGGINGFACE.enabled) {
    serviceStatus.huggingFace = 'configured';
    availableCapabilities.push('hf_chat', 'hf_vision');
  }

  res.json({ 
    status: 'active', 
    service: 'Shahin GRC Multi-Modal AI Assistant',
    version: '2.0.0',
    capabilities: [...new Set(availableCapabilities)], // Remove duplicates
    services: serviceStatus,
    intelligentRouting: true,
    autoFallback: true,
    timestamp: new Date().toISOString()
  });
});

// Initialize AI system
app.get('/api/ai/initialize', (req, res) => {
  res.json({ 
    status: 'initialized',
    agent: 'ARIA',
    language: 'ar-SA',
    features: {
      chat: true,
      voice_recognition: true,
      text_to_speech: true,
      image_analysis: true,
      document_processing: true
    }
  });
});

// Enhanced chat endpoint with multi-source AI
app.post('/api/ai/chat', async (req, res) => {
  try {
    const { message, context } = req.body;
    
    // Use intelligent AI routing
    const result = await routeToAvailableAI('chat', { message, context });
    
    res.json({
      type: 'text',
      message: result.message,
      source: result.source,
      context: {
        agent: 'ARIA',
        timestamp: new Date().toISOString(),
        mode: context?.mode || 'chat',
        aiService: result.source
      }
    });
    
  } catch (error) {
    console.error('Chat error:', error);
    res.status(500).json({ error: 'Internal server error', details: error.message });
  }
});

// Enhanced image analysis endpoint with multi-source AI
app.post('/api/ai/analyze-image', async (req, res) => {
  try {
    const { image, context } = req.body;
    
    // Use intelligent AI routing for image analysis
    const result = await routeToAvailableAI('image', { image, context });
    
    res.json({
      analysis: result.analysis || result.message,
      confidence: result.confidence || 0.85,
      source: result.source,
      detected_elements: result.tags || ['text', 'document', 'content'],
      language_detected: ['ar', 'en'],
      timestamp: new Date().toISOString()
    });
    
  } catch (error) {
    console.error('Image analysis error:', error);
    res.status(500).json({ 
      error: 'Image analysis failed', 
      details: error.message,
      fallback: true
    });
  }
});

// Document analysis endpoint
app.post('/api/ai/analyze-document', (req, res) => {
  try {
    const { file, context } = req.body;
    
    // Simulate document analysis
    setTimeout(() => {
      const documentAnalysis = [
        `ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªÙ†Ø¯ "${file.name}" Ø¨Ù†Ø¬Ø§Ø­. ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ø§Ù„ÙŠØ© ÙˆØªÙ‚Ø§Ø±ÙŠØ± Ø£Ø¯Ø§Ø¡ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ ØªØ­Ù„ÙŠÙ„Ù‡Ø§.`,
        `Ø§Ù„Ù…Ø³ØªÙ†Ø¯ ÙŠØªØ¶Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù‡Ù…Ø© Ø­ÙˆÙ„ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ ÙˆØ§Ù„Ù…Ø®Ø§Ø·Ø±. ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø¥Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ÙˆØªÙ‚Ø¯ÙŠÙ… ØªÙˆØµÙŠØ§Øª.`,
        `ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³ØªÙ†Ø¯ ÙŠØ¸Ù‡Ø± Ù…Ø¤Ø´Ø±Ø§Øª Ø£Ø¯Ø§Ø¡ ÙˆÙ…Ù‚Ø§ÙŠÙŠØ³ Ù…Ø§Ù„ÙŠØ©. ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø­Ø§Ù„ÙŠ.`,
        `Ø§Ù„Ù…Ø³ØªÙ†Ø¯ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø³ÙŠØ§Ø³Ø§Øª ÙˆØ¥Ø¬Ø±Ø§Ø¡Ø§Øª. ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø±Ø§Ø¬Ø¹ØªÙ‡Ø§ ÙˆØªÙ‚Ø¯ÙŠÙ… Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ù„Ù„ØªØ­Ø³ÙŠÙ†.`
      ];
      
      const analysis = documentAnalysis[Math.floor(Math.random() * documentAnalysis.length)];
      
      res.json({
        analysis: analysis,
        document_type: file.type,
        file_size: file.size,
        processing_time: Math.round(1000 + Math.random() * 3000),
        extracted_data: {
          pages: Math.ceil(Math.random() * 10),
          words: Math.ceil(Math.random() * 5000),
          tables: Math.ceil(Math.random() * 5),
          images: Math.ceil(Math.random() * 3)
        }
      });
    }, 1500 + Math.random() * 2500);
    
  } catch (error) {
    console.error('Document analysis error:', error);
    res.status(500).json({ error: 'Document analysis failed' });
  }
});

// Voice processing endpoint
app.post('/api/ai/process-voice', upload.single('audio'), (req, res) => {
  try {
    const { language } = req.body;
    const audioFile = req.file;
    
    // Simulate voice processing
    setTimeout(() => {
      const voiceResponses = [
        {
          transcription: 'Ù…Ø±Ø­Ø¨Ø§Ù‹ØŒ Ø£Ø±ÙŠØ¯ Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ø¹Ù† Ø®Ø¯Ù…Ø§ØªÙƒÙ…',
          response: 'Ø£Ù‡Ù„Ø§Ù‹ ÙˆØ³Ù‡Ù„Ø§Ù‹! ÙŠØ³Ø¹Ø¯Ù†ÙŠ Ø£Ù† Ø£Ø®Ø¨Ø±Ùƒ Ø¹Ù† Ø®Ø¯Ù…Ø§Øª Ø´Ø§Ù‡ÙŠÙ† Ù„Ù„Ø­ÙˆÙƒÙ…Ø©. Ù†Ø­Ù† Ù†Ù‚Ø¯Ù… Ø­Ù„ÙˆÙ„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø± ÙˆØ§Ù„Ø§Ù…ØªØ«Ø§Ù„.'
        },
        {
          transcription: 'ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ¬Ø±Ø¨Ø© Ù…Ø¬Ø§Ù†ÙŠØ©ØŸ',
          response: 'ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ¬Ø±Ø¨Ø© Ù…Ø¬Ø§Ù†ÙŠØ© Ù„Ù…Ø¯Ø© 30 ÙŠÙˆÙ…Ø§Ù‹. Ø³Ø£Ø³Ø§Ø¹Ø¯Ùƒ ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø­Ø³Ø§Ø¨ ÙˆØ§Ù„Ø¨Ø¯Ø¡ ÙÙˆØ±Ø§Ù‹.'
        },
        {
          transcription: 'Ø£Ø­ØªØ§Ø¬ Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø®Ø§Ø·Ø±',
          response: 'Ø¨Ø§Ù„Ø·Ø¨Ø¹! ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ ØªØ­Ù„ÙŠÙ„ ÙˆØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø­Ø¯Ø« ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.'
        }
      ];
      
      const randomResponse = voiceResponses[Math.floor(Math.random() * voiceResponses.length)];
      
      res.json({
        transcription: randomResponse.transcription,
        response: randomResponse.response,
        confidence: 0.88 + Math.random() * 0.11,
        duration: Math.random() * 10 + 2 // 2-12 seconds
      });
    }, 800 + Math.random() * 1200);
    
  } catch (error) {
    console.error('Voice processing error:', error);
    res.status(500).json({ error: 'Voice processing failed' });
  }
});

// Start server
app.listen(PORT, () => {
  console.log(`ðŸš€ Shahin GRC AI Backend running on port ${PORT}`);
  console.log(`ðŸ¤– AI Agent APIs available at http://localhost:${PORT}/api/ai/`);
  console.log(`ðŸ“Š Health check: http://localhost:${PORT}/api/ai/health`);
});

module.exports = app;